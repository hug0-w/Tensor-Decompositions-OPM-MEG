{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c2793ed",
      "metadata": {
        "id": "1c2793ed"
      },
      "source": [
        "# Rank selection (choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "U67rbvclmhqb",
      "metadata": {
        "id": "U67rbvclmhqb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from scipy.stats import zscore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bdc996ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc996ca",
        "outputId": "71e84952-f523-4eb8-fb0c-316698810e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 14 09:05:29 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "GlpH-TtClyvh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpH-TtClyvh",
        "outputId": "0d19dab5-8d7a-447a-ff63-d2bfe5ec6bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current Directory: /content/drive/My Drive/OPM-MEG\n"
          ]
        }
      ],
      "source": [
        "# Import google drive mounting module\n",
        "from google.colab import drive\n",
        "\n",
        "# Import os/path lib to navigate the colab directory.\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "# Mount Google Drive at the default location\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "# Define the path to your desired folder\n",
        "path = '/content/drive/My Drive/OPM-MEG'\n",
        "# Change to that directory\n",
        "os.chdir(path)\n",
        "# Verify the current working directory\n",
        "print(\"Current Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6oxVr6oprRmK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oxVr6oprRmK",
        "outputId": "d47408d8-a7d4-4989-b975-9b24c8331093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensor-Decompositions-OPM-MEG'...\n",
            "remote: Enumerating objects: 263, done.\u001b[K\n",
            "remote: Counting objects: 100% (263/263), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 263 (delta 114), reused 203 (delta 64), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (263/263), 26.39 MiB | 25.19 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "Collecting tensorly\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorly) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorly) (1.16.3)\n",
            "Downloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorly\n",
            "Successfully installed tensorly-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hug0-w/Tensor-Decompositions-OPM-MEG/\n",
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "iqkVeiu7mPih",
      "metadata": {
        "id": "iqkVeiu7mPih"
      },
      "outputs": [],
      "source": [
        "mat_path = \"choice_pow_trial_chan_fbin_time_ds500_tpos.mat\"\n",
        "\n",
        "with h5py.File(mat_path, \"r\") as f:\n",
        "\n",
        "    # --- main data ---\n",
        "    # HDF5 reads MATLAB v7.3 arrays with transposed dimensions.\n",
        "    # MATLAB Saved: [Trials, Chan, Freqs, Time]\n",
        "    # Python Reads: (Time, Freqs, Chan, Trials)\n",
        "    Pow = np.array(f[\"Pow\"])\n",
        "\n",
        "    freq = np.array(f[\"freq\"]).squeeze()\n",
        "    time = np.array(f[\"time\"]).squeeze()\n",
        "\n",
        "    freqs_hz = np.array(f[\"freqs_hz\"]).squeeze()\n",
        "\n",
        "    ds_fs = float(np.array(f[\"ds_fs\"]).squeeze())\n",
        "    fs_orig = float(np.array(f[\"fs_orig\"]).squeeze())\n",
        "\n",
        "    # --- channel labels (MATLAB cellstr) ---\n",
        "    # MATLAB cell arrays of strings are stored as object references in HDF5\n",
        "    ch_names_refs = f[\"chan_lbl\"][()]\n",
        "    chan_lbl = []\n",
        "    for r in ch_names_refs.flatten():\n",
        "        s = f[r][()]\n",
        "        # MATLAB v7.3 stores strings as uint16 (utf-16le)\n",
        "        chan_lbl.append(s.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\"))\n",
        "\n",
        "    # --- MNE metadata ---\n",
        "    mne_grp = f[\"mne\"]\n",
        "\n",
        "    ch_names_refs = mne_grp[\"ch_names\"][()]\n",
        "    mne_ch_names = []\n",
        "    for r in ch_names_refs.flatten():\n",
        "        s = f[r][()]\n",
        "        mne_ch_names.append(s.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\"))\n",
        "\n",
        "    ch_pos_m = np.array(mne_grp[\"ch_pos_m\"], dtype=float)\n",
        "    # MATLAB stored (N, 3), HDF5 reads (3, N). Transpose to get (N_chan, 3).\n",
        "    if ch_pos_m.shape[0] == 3 and ch_pos_m.shape[1] != 3:\n",
        "        ch_pos_m = ch_pos_m.T\n",
        "\n",
        "    # Decode coordinate frame string (e.g., 'head')\n",
        "    coord_frame_data = mne_grp[\"coord_frame\"][()]\n",
        "    try:\n",
        "        coord_frame = coord_frame_data.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\")\n",
        "    except AttributeError:\n",
        "        # Fallback if it loaded as a simple byte string or char\n",
        "        coord_frame = str(coord_frame_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "E1SVS1VXpl3T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1SVS1VXpl3T",
        "outputId": "c62219ff-9688-4dc4-8759-2aedbdcbd204"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(751, 35, 121, 195)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Pow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Iw9N66ORosCj",
      "metadata": {
        "id": "Iw9N66ORosCj"
      },
      "outputs": [],
      "source": [
        "Pow_T = Pow.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ygvnNSV8c5rC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygvnNSV8c5rC",
        "outputId": "fb7bdb75-ceba-4cf0-90d4-c966e3691d90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 121, 35, 751)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Pow_T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "BkHh5tYtE6Hc",
      "metadata": {
        "id": "BkHh5tYtE6Hc"
      },
      "outputs": [],
      "source": [
        "log_Pow = np.log1p(Pow_T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Dzj0ZNJRDzmL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzj0ZNJRDzmL",
        "outputId": "e85386ba-58b7-42d5-9665-8718fa450a7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.True_"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "is_true = np.all(log_Pow >0)\n",
        "\n",
        "is_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "tkKwKyPutjn8",
      "metadata": {
        "id": "tkKwKyPutjn8"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "log_Pow_torch = torch.as_tensor(log_Pow, device=device, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "hht5FAnfqNG_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hht5FAnfqNG_",
        "outputId": "fb22f261-4c55-4623-88c3-01a73bae8838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "log_Pow_torch.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Wks27a-7qsZO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wks27a-7qsZO",
        "outputId": "ed95b4c7-536e-46f7-f5e1-4ece3c961f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OPM-MEG/Tensor-Decompositions-OPM-MEG\n"
          ]
        }
      ],
      "source": [
        "%cd Tensor-Decompositions-OPM-MEG/\n",
        "from src.tools.rankselection import  rank_stability, stability_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "-sIls75Lq2IA",
      "metadata": {
        "id": "-sIls75Lq2IA"
      },
      "outputs": [],
      "source": [
        "import tensorly as tl\n",
        "tl.set_backend('pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "INRfWJApsPs5",
      "metadata": {
        "id": "INRfWJApsPs5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "hCMGXB7qSPDV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCMGXB7qSPDV",
        "outputId": "af1221c8-2569-4c95-d3c0-37f555978118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [2:47:04<00:00, 1253.04s/it]\n"
          ]
        }
      ],
      "source": [
        "ranks = np.arange(13,21,1)\n",
        "\n",
        "stabilities = []\n",
        "stds = []\n",
        "\n",
        "for i in tqdm(ranks):\n",
        "\n",
        "    stability,std = rank_stability(log_Pow_torch,i,n_repeats=10)\n",
        "\n",
        "\n",
        "    stabilities.append(stability)\n",
        "    stds.append(std)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}