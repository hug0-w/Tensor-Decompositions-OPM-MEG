{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c2793ed",
      "metadata": {
        "id": "1c2793ed"
      },
      "source": [
        "# Rank selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "U67rbvclmhqb",
      "metadata": {
        "id": "U67rbvclmhqb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bdc996ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc996ca",
        "outputId": "798bfe49-a205-41fe-fc36-43405a86a835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan  9 12:42:01 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "GlpH-TtClyvh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlpH-TtClyvh",
        "outputId": "9ef9eae5-ed12-4e5b-86b3-5766ead5843a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Current Directory: /content/drive/My Drive/OPM-MEG\n"
          ]
        }
      ],
      "source": [
        "# Import google drive mounting module\n",
        "from google.colab import drive\n",
        "\n",
        "# Import os/path lib to navigate the colab directory.\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "# Mount Google Drive at the default location\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "# Define the path to your desired folder\n",
        "path = '/content/drive/My Drive/OPM-MEG'\n",
        "# Change to that directory\n",
        "os.chdir(path)\n",
        "# Verify the current working directory\n",
        "print(\"Current Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6oxVr6oprRmK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oxVr6oprRmK",
        "outputId": "1ca7a944-8b4e-4365-e020-0b6ea51f55ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensor-Decompositions-OPM-MEG'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 66 (delta 15), reused 64 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (66/66), 83.76 KiB | 708.00 KiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Requirement already satisfied: tensorly in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorly) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorly) (1.16.3)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hug0-w/Tensor-Decompositions-OPM-MEG/\n",
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "iqkVeiu7mPih",
      "metadata": {
        "id": "iqkVeiu7mPih"
      },
      "outputs": [],
      "source": [
        "mat_path = \"outcome_pow_trial_chan_fbin_time_ds500_tpos.mat\"\n",
        "\n",
        "with h5py.File(mat_path, \"r\") as f:\n",
        "\n",
        "    # --- main data ---\n",
        "    # HDF5 reads MATLAB v7.3 arrays with transposed dimensions.\n",
        "    # MATLAB Saved: [Trials, Chan, Freqs, Time]\n",
        "    # Python Reads: (Time, Freqs, Chan, Trials)\n",
        "    Pow = np.array(f[\"Pow\"])\n",
        "\n",
        "    freq = np.array(f[\"freq\"]).squeeze()\n",
        "    time = np.array(f[\"time\"]).squeeze()\n",
        "\n",
        "    # Removed: fbins = np.array(f[\"fbins\"])\n",
        "    freqs_hz = np.array(f[\"freqs_hz\"]).squeeze()\n",
        "\n",
        "    ds_fs = float(np.array(f[\"ds_fs\"]).squeeze())\n",
        "    fs_orig = float(np.array(f[\"fs_orig\"]).squeeze())\n",
        "\n",
        "    # --- channel labels (MATLAB cellstr) ---\n",
        "    # MATLAB cell arrays of strings are stored as object references in HDF5\n",
        "    ch_names_refs = f[\"chan_lbl\"][()]\n",
        "    chan_lbl = []\n",
        "    for r in ch_names_refs.flatten():\n",
        "        s = f[r][()]\n",
        "        # MATLAB v7.3 stores strings as uint16 (utf-16le)\n",
        "        chan_lbl.append(s.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\"))\n",
        "\n",
        "    # --- MNE metadata ---\n",
        "    mne_grp = f[\"mne\"]\n",
        "\n",
        "    ch_names_refs = mne_grp[\"ch_names\"][()]\n",
        "    mne_ch_names = []\n",
        "    for r in ch_names_refs.flatten():\n",
        "        s = f[r][()]\n",
        "        mne_ch_names.append(s.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\"))\n",
        "\n",
        "    ch_pos_m = np.array(mne_grp[\"ch_pos_m\"], dtype=float)\n",
        "    # MATLAB stored (N, 3), HDF5 reads (3, N). Transpose to get (N_chan, 3).\n",
        "    if ch_pos_m.shape[0] == 3 and ch_pos_m.shape[1] != 3:\n",
        "        ch_pos_m = ch_pos_m.T\n",
        "\n",
        "    # Decode coordinate frame string (e.g., 'head')\n",
        "    coord_frame_data = mne_grp[\"coord_frame\"][()]\n",
        "    try:\n",
        "        coord_frame = coord_frame_data.tobytes().decode(\"utf-16le\").rstrip(\"\\x00\")\n",
        "    except AttributeError:\n",
        "        # Fallback if it loaded as a simple byte string or char\n",
        "        coord_frame = str(coord_frame_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "E1SVS1VXpl3T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1SVS1VXpl3T",
        "outputId": "ca412964-636e-4097-b747-99128370f116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(751, 35, 121, 195)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Pow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Iw9N66ORosCj",
      "metadata": {
        "id": "Iw9N66ORosCj"
      },
      "outputs": [],
      "source": [
        "log_Pow = np.log(Pow+1e-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7bAW6EUNqeqx",
      "metadata": {
        "id": "7bAW6EUNqeqx"
      },
      "outputs": [],
      "source": [
        "log_Pow = log_Pow.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "tkKwKyPutjn8",
      "metadata": {
        "id": "tkKwKyPutjn8"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "log_Pow_torch = torch.as_tensor(log_Pow, device=device, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wks27a-7qsZO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wks27a-7qsZO",
        "outputId": "1d6d1071-550c-4cfb-f2a9-88b921699537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/OPM-MEG/Tensor-Decompositions-OPM-MEG\n"
          ]
        }
      ],
      "source": [
        "%cd Tensor-Decompositions-OPM-MEG/\n",
        "from src.tools.stability import rank_variance, rank_stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "-sIls75Lq2IA",
      "metadata": {
        "id": "-sIls75Lq2IA"
      },
      "outputs": [],
      "source": [
        "import tensorly as tl\n",
        "tl.set_backend('pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "INRfWJApsPs5",
      "metadata": {
        "id": "INRfWJApsPs5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8AbS6PEprq0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AbS6PEprq0a",
        "outputId": "f6ea73b0-2353-4a80-8836-c364855ca8be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [25:30<00:00, 765.14s/it]\n"
          ]
        }
      ],
      "source": [
        "ranks = np.arange(1,16,1)\n",
        "\n",
        "variances = []\n",
        "\n",
        "for i in tqdm(ranks):\n",
        "\n",
        "    variance = rank_variance(log_Pow_torch,i)\n",
        "\n",
        "\n",
        "    variances.append(variance)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "OPM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
